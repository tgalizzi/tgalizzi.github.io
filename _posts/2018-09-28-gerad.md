---
layout: distill
title: GERAD, Montréal
description: Factorisation de matrices creuses pour l'optimisation
date: 2019-09-28 21:01:00
img: assets/img/gerad.png


# Optionally, you can add a table of contents to your post.
# NOTES:
#   - make sure that TOC names match the actual section names
#     for hyperlinks within the post to work correctly.
#   - we may want to automate TOC generation in the future using
#     jekyll-toc plugin (https://github.com/toshimaru/jekyll-toc).
toc:
  - name: Le contexte de mon stage
  - name: Ma mission
  - name: Bilan

# Below is an example of injecting additional post-specific styles.
# If you use this post as a template, delete this _styles block.
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }

---

## Le contexte de mon stage

Pour ce stage de deuxième année d'école d'ingénieur, j'ai eu la chance de travailler pour le Groupe d'études et de recherche en analyse des décisions (GERAD), un centre de recherche interuniversitaire localisé à Montréal.




## Ma mission

L'objectif de mon stage était de modifier deux module de factorisation de Cholesky existante et très utilisé par le laboratoire (mais aussi par les utilisateurs de Julia !), [LDLFactorizations](https://github.com/JuliaSmoothOptimizers/LimitedLDLFactorizations.jl) et [LimitedLDLFactorizations](https://github.com/JuliaSmoothOptimizers/LimitedLDLFactorizations.jl) afin de rendre les modules plus fexibles et performants.
La performance des calculs en mémoire était une des plus grandes problématiques de ce stage. En optimisation, il est courant de rencontrer des systèmes avec des millions de paramètres et d'équations, qui se traduise par d'immense matrices. Lorsqu'on manipule des matrices de cette taille, ces problématiques deviennent primordiales si l'on veut pouvoir les factoriser.

### La factorisation de Cholesky alternative ou decomposition LDLt

Pour une matrice **A** possédant les bonnes propriétés, la **decomposition LDLt revient** à trouver une matrice **D** diagonale et **L** triangulaire telle que $$ A = L D L^t $$

Cette méthode permet, pour les systèmes adéquats, une très grande efficacité et stabilité numérique.

### Matrices Creuses

Bien que plutôt simple à calculer, cette factorisation se revèle bien plus complexe lorsque les performances en calculs et en mémoire sont mis au premier plan. En optimisation, les matrices, souvent énormes, possèdent en pratique généralement beaucoup d'entrée nulles.
Il est alors très intéressant en informatique de stocker ces matrices particulière en ométant volontairement ces entrées, seules les valeurs non-nulles sont stockées en mémoire.


</div>
<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/gerad/sparse.png" title="sparse matrix" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Un exemple de matrice creuse. Les valeurs non-nulles sont représentées en noir.
</div>



Au profit de la mémoire, le stockage de ces matrices devient bien plus complexe, et par conséquence, leur manipulation.


</div>
<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/gerad/sparse.png" title="sparse matrix" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Un exemple de matrice creuse. Les valeurs non-nulles sont représentées en noir.
</div>


### Pourquoi cette factorisation est utile en optimisation ?

La decomposition de Cholesky est principalement utilisé pour résoudre les systèmes d'équations linéaire $$Ax=b$$.
En optimisation, elle permet notamment de résoudre les equations aux moindres carrées linéaires. Elle est également utile pour les méthodes de descente de gradient en optimisation non linéaire.

## Bilan

Cette première expérience en laboratoire m'a permis de me familiariser avec le monde de la recherche.


<br/><br/>
<br/><br/>
<br/><br/>